{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02aa98d",
   "metadata": {},
   "source": [
    "# generate summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/GFM\") # your project root directory\n",
    "from GraphCLIP.generate_summary_api import *\n",
    "from openai import OpenAI\n",
    "# api_key = 'your_api_key'\n",
    "# client = OpenAI(api_key=api_key)\n",
    "client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea261151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, task_name):\n",
    "        self.model = \"graphclip\"\n",
    "        self.model_id = \"exp1\"\n",
    "        self.task_name = task_name\n",
    "        self.input_dim = 128\n",
    "        self.compress_function = \"none\"\n",
    "        self.cache_compress = False\n",
    "        self.seed = 0\n",
    "        self.is_logging = False\n",
    "        self.num_workers = 0\n",
    "        self.device = None\n",
    "        self.pattern = \"simple\"\n",
    "\n",
    "args = Args(task_name=\"pretrain\")\n",
    "pretrain_exps = {\n",
    "    \"exp1\": pretrain,\n",
    "    \"exp2\": pretrain,\n",
    "    \"exp3\": pretrain_exp3,\n",
    "    \"exp4\": pretrain_exp4,\n",
    "}\n",
    "pretrain_dict = pretrain_exps[args.model_id]\n",
    "# recommmed run one by one\n",
    "pretrain_dict = {\n",
    "    'Cora': cora,\n",
    "    # 'ACM': acm,\n",
    "    # 'DBLP': dblp,\n",
    "    # 'Reddit': reddit,\n",
    "    # 'Texas': texas,\n",
    "    # 'Wisconsin': wisconsin,\n",
    "    # 'Cornell': cornell,\n",
    "    # 'IMDB': imdb,\n",
    "    \n",
    "    # 'Photo': photo,\n",
    "    # 'Computers': computers,\n",
    "    # 'Amazon': amazon,\n",
    "    # 'Amazon-HeTGB': amazonh,\n",
    "    # 'HIV': hiv,\n",
    "    # 'COX2': cox2,\n",
    "    # 'PROTEINS': proteins,\n",
    "    # 'ENZYMES': enzymes,\n",
    "    # 'FB15K-237': fb15k237,\n",
    "    # 'NELL': nell,\n",
    "\n",
    "    # # large-scale datasets\n",
    "    # 'ogbn-arxiv': ogbn_arxiv,\n",
    "    # 'Elliptic': elliptic\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177204f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_request(args, pretrain_dict, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6cc3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"{ROOT_DIR}/GraphCLIP/api/output_dict.json\"\n",
    "with open(save_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    output_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8d3cf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Dataset: FB15K-237 ##############\n",
      "Batch ID: batch_69495d71f0d481909545f2c2bc2f00de \n",
      "Status: completed Request Counts: BatchRequestCounts(completed=6000, failed=0, total=6000)\n",
      "Batch ID: batch_69495dc6ee088190ba693153810ba34e \n",
      "Status: completed Request Counts: BatchRequestCounts(completed=6000, failed=0, total=6000)\n",
      "Batch ID: batch_69495dec7878819099e66099e6e15fdc \n",
      "Status: completed Request Counts: BatchRequestCounts(completed=2505, failed=0, total=2505)\n"
     ]
    }
   ],
   "source": [
    "# check status\n",
    "for name in list(output_dict.keys()):\n",
    "    if name in ['FB15K-237']:\n",
    "        print(f\"############ Dataset: {name} ##############\")\n",
    "        for batch_id in output_dict[name][\"batch_ids\"]:\n",
    "            print(f\"Batch ID: {batch_id} \\n\"\n",
    "                f\"Status: {client.batches.retrieve(batch_id).status} \"\n",
    "                f\"Request Counts: {client.batches.retrieve(batch_id).request_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd629f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total retry requests: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/shenghua/Graph-Foundation-Library/datasets/FB15K-237/preprocess/graphclip/retry_0.jsonl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if failed, retry\n",
    "name = \"FB15K-237\"\n",
    "get_fail_requests(client, name)\n",
    "retry_failed_requests(client, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6179e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6000 results from batch batch_69495d71f0d481909545f2c2bc2f00de\n",
      "input_tokens=11810217, avg=1968.37\n",
      "output_tokens=2431769, avg=405.29\n",
      "Loaded 6000 results from batch batch_69495dc6ee088190ba693153810ba34e\n",
      "input_tokens=11829813, avg=1971.64\n",
      "output_tokens=2419807, avg=403.30\n",
      "Loaded 2505 results from batch batch_69495dec7878819099e66099e6e15fdc\n",
      "input_tokens=4912955, avg=1961.26\n",
      "output_tokens=1017221, avg=406.08\n",
      "Merged summaries saved to /home/shenghua/Graph-Foundation-Library/datasets/FB15K-237/preprocess/graphclip/summary.json\n"
     ]
    }
   ],
   "source": [
    "# generate final summary\n",
    "for name in output_dict.keys():\n",
    "    if name in ['FB15K-237']:\n",
    "        merge_batch_summaries(\n",
    "            item_list_path=output_dict[name][\"item_list_path\"],\n",
    "            batch_ids=output_dict[name][\"batch_ids\"],\n",
    "            summary_path=output_dict[name][\"summary_path\"],\n",
    "            client=client\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45921c6b",
   "metadata": {},
   "source": [
    "### some tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list recent batches\n",
    "batches = client.batches.list()\n",
    "for b in batches.data[:10]:\n",
    "    print(f\"ID: {b.id}, Status: {b.status}, Model: {b.model}, {b.request_counts}, usage: {b.usage.output_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c131c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check batch status\n",
    "client.batches.retrieve('batch_69417358f81481908a1ec508f785607c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e26cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel batch\n",
    "client.batches.cancel('batch_693e726592b08190b1c4e651d5588f3e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error check\n",
    "file_id = client.batches.retrieve('batch_6946da0915ec81909dfa81ed2a96cbe5').error_file_id\n",
    "result_bytes = client.files.content(file_id)\n",
    "result_lines = result_bytes.text.splitlines()\n",
    "result_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b447f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all summaries added\n",
    "save_path = f\"{ROOT_DIR}/GraphCLIP/api/output_dict.json\"\n",
    "with open(save_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    output_dir = json.load(f)\n",
    "\n",
    "for name in output_dir.keys():\n",
    "    check_summary(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3602e76",
   "metadata": {},
   "source": [
    "# generate node feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67aa7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/shenghua/Graph-Foundation-Library\")\n",
    "from GraphCLIP.generate_feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074b92be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression function is None.\n",
      "Set random seed to 0\n",
      "Pretrain datasets: Cora, ACM, DBLP\n",
      "> Loading existing embeddings from: /home/shenghua/Graph-Foundation-Library/datasets/Cora/preprocess/graphclip/node_feature.pt\n",
      "> Loading existing embeddings from: /home/shenghua/Graph-Foundation-Library/datasets/ACM/preprocess/graphclip/node_feature.pt\n",
      "> Loading existing embeddings from: /home/shenghua/Graph-Foundation-Library/datasets/DBLP/preprocess/graphclip/node_feature.pt\n",
      "Finished generating node features for all datasets.\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, task_name):\n",
    "        self.model = \"graphclip\"\n",
    "        self.model_id = \"exp3\"\n",
    "        self.task_name = task_name\n",
    "        self.pattern = \"simple\"\n",
    "        self.input_dim = 384\n",
    "        self.compress_function = \"none\"\n",
    "        self.cache_compress = False\n",
    "        self.seed = 0\n",
    "        self.is_logging = False\n",
    "        self.num_workers = 0\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.checkpoints = str(ROOT_DIR / \"checkpoints\")\n",
    "\n",
    "args = Args(task_name=\"pretrain\")\n",
    "pretrain_exps = {\n",
    "    \"exp1\": pretrain,\n",
    "    \"exp2\": pretrain,\n",
    "    \"exp3\": pretrain_exp3,\n",
    "    \"exp4\": pretrain_exp4,\n",
    "}\n",
    "pretrain_dict = pretrain_exps[args.model_id]\n",
    "exp = ExpPretrainGraphCLIP(args, pretrain_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f94e38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process FB15K-237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14505/14505 [00:15<00:00, 910.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from GraphCLIP.utils.process import parse_source_data\n",
    "all_source_graph = []\n",
    "for name, data in exp.pretrain_dict.items():\n",
    "    source_graph = parse_source_data(name, data)\n",
    "    all_source_graph.extend(source_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed338a43",
   "metadata": {},
   "source": [
    "# generate target sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006e1407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenghua/anaconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression function is None.\n",
      "Set random seed to 0\n",
      "Target dataset: PROTEINS\n",
      "Average degree: 3.73\n",
      "Is undirected: True\n",
      "> Loading existing embeddings from: /home/shenghua/Graph-Foundation-Library/datasets/PROTEINS/preprocess/graphclip/node_feature.pt\n",
      "Finished generating node features for PROTEINS dataset.\n",
      "Loading pre-generated subgraphs...\n",
      "Loaded pre-generated subgraphs from /home/shenghua/Graph-Foundation-Library/datasets/PROTEINS/preprocess/graphclip/sub_list(none).pt. And added PE feature.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/shenghua/Graph-Foundation-Library\")\n",
    "from gen_target_subg import *\n",
    "from GraphCLIP.utils.args import Arguments\n",
    "from data_provider import *\n",
    "args = Arguments().parser.parse_args([])\n",
    "args.model = \"graphclip\"\n",
    "args.model_id = \"exp2\"\n",
    "args.exp_id = \"exp2\"\n",
    "args.task_name = \"graph\"\n",
    "args.seed = 0\n",
    "args.is_logging = False\n",
    "args.compress_function = \"none\"\n",
    "args.input_dim = 384\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args.sampler = 'rw'#'khop'\n",
    "args.walk_step = 256\n",
    "args.batch_size = 32768\n",
    "pretrain_exps = {\n",
    "    \"exp1\": pretrain,\n",
    "    \"exp2\": pretrain,\n",
    "    \"exp3\": pretrain_exp3,\n",
    "    \"exp4\": pretrain_exp4,\n",
    "}\n",
    "pretrain_dict = pretrain_exps[args.model_id]\n",
    "\n",
    "exps = {\n",
    "    f\"exp{i}\": {\n",
    "        \"node\": globals()[f\"NC_exp{i}\"],\n",
    "        \"edge\": globals()[f\"EC_exp{i}\"],\n",
    "        \"graph\": globals()[f\"GC_exp{i}\"],\n",
    "    }\n",
    "    for i in range(0, 5)\n",
    "}\n",
    "for name, dataset in exps[args.exp_id][args.task_name].items():\n",
    "    exp = ExpDownstreamBatchGraphCLIP(args, pretrain_dict, name, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
